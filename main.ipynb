{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1000,3)\n",
    "x = np.concatenate((x,np.ones((1000,1))), axis=1)\n",
    "y = np.expand_dims(np.apply_along_axis(lambda x : np.matmul(x,[5,3,1.5,6]), 1, x),axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def accuracy(y,y_predicted):\n",
    "    #return (y_predicted == y).sum()/len(y)\n",
    "\n",
    "# As it's linear regression, I'll def\n",
    "# ine the percentaage error by taking the max abs error and divide it on predicted y then then the accurace will 1 - percentage error\n",
    "def accuracy(y_test, y_predicted):\n",
    "    return 1 - (np.max((abs(y_predicted - y_test))/y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights (pseudoinverse):  [[5.  3.  1.5 6. ]]\n"
     ]
    }
   ],
   "source": [
    "#Minimizing Sum of Error Squares Estimation by Pseudoinverse\n",
    "def sum_squared(x,y):\n",
    "    xT = np.transpose(x) \n",
    "    pseudoinverse = inv(np.matrix(np.matmul(xT,x)))\n",
    "    temp = np.matmul(xT,y)\n",
    "    weights = np.matmul(pseudoinverse,temp)\n",
    "    return weights\n",
    "\n",
    "weights = sum_squared(x_train,y_train)\n",
    "\n",
    "print(\"Weights (pseudoinverse): \", np.transpose(weights))\n",
    "\n",
    "def pseudoinverse_predict(xTrain, yTrain, x):\n",
    "    w = sum_squared(xTrain, yTrain)\n",
    "    return np.matmul(x,w);\n",
    "\n",
    "y_predicted = pseudoinverse_predict(x_train,y_train,x_test)\n",
    "#print(\"Accuracy (PseudoInverse): \",accuracy(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss_Funtion(y_predicted, y):\n",
    "    return np.sum(np.square(np.subtract(y,y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights (gradient descent):  [[5.  3.  1.5 6. ]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent_fit(x, y, learning_rate = 0.0001, iterations = 10000):\n",
    "    weights = np.random.rand(len(x[0]),1)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        gradient = -2 * np.matmul(np.transpose(x), (y - (np.matmul(x, weights))))\n",
    "        weights = np.subtract(weights, (learning_rate * gradient))\n",
    "    return weights\n",
    "\n",
    "def gradient_descent_predict(xTrain,yTrain,x):\n",
    "    w = gradient_descent_fit(xTrain, yTrain)\n",
    "    return np.matmul(x, w);\n",
    "\n",
    "print(\"Weights (gradient descent): \", np.transpose(gradient_descent_fit(x_train,y_train)))\n",
    "y_predicted = gradient_descent_predict(x_train,y_train,x_test)\n",
    "#print(\"Accuracy (gradient descent): \", accuracy(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Housing Prices Dataset\n",
    "hdf = pd.DataFrame(pd.read_csv(\"USA_Housing.csv\"))\n",
    "\n",
    "maxValue= [hdf[\"Price\"].max(), hdf[\"Avg. Area Income\"].max(), hdf[\"Avg. Area House Age\"].max(), hdf[\"Avg. Area Number of Rooms\"].max(), hdf[\"Avg. Area Number of Bedrooms\"].max(), hdf[\"Area Population\"].max()]\n",
    "\n",
    "#Normalization to make values between 0 and 1\n",
    "hdf[\"Price\"] /= maxValue[0]\n",
    "hdf[\"Avg. Area Income\"] /= maxValue[1]\n",
    "hdf[\"Avg. Area House Age\"] /= maxValue[2]\n",
    "hdf[\"Avg. Area Number of Rooms\"] /= maxValue[3]\n",
    "hdf[\"Avg. Area Number of Bedrooms\"] /= maxValue[4]\n",
    "hdf[\"Area Population\"] /= maxValue[5]\n",
    "\n",
    "hdf = hdf.to_numpy()\n",
    "\n",
    "df_train, df_test = train_test_split(hdf)\n",
    "\n",
    "housing_Ytrain = (df_train[:,5]).reshape(-1,1)\n",
    "housing_Xtrain = df_train[:,0:5]\n",
    "housing_Xtrain = housing_Xtrain.astype('float32')\n",
    "\n",
    "housing_Ytest = (df_test[:,5]).reshape(-1,1)\n",
    "housing_Xtest = df_test[:,0:5]\n",
    "housing_Xtest = housing_Xtest.astype('float32')\n",
    "\n",
    "\n",
    "#predict using Pseudoinverse\n",
    "#y_predicted = pseudoinverse_predict(housing_Xtrain, housing_Ytrain, housing_Xtest)\n",
    "#print(\"Accuracy HousingPrice (PseudoInverse): \",accuracy(housing_Ytest, y_predicted))\n",
    "\n",
    "#predict using Gradient Descent\n",
    "y_predicted = gradient_descent_predict(housing_Xtrain, housing_Ytrain, housing_Xtest)\n",
    "#print(\"Accuracy HousingPrice (gradient descent): \",accuracy(housing_Ytest, y_predicted))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c07fd7d0846095743f2312e27acc14d43a7db7e932b66e06ea42ef738530e912"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
